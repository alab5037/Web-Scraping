{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, my objective is to juxtapose how climate change is viewed by the left and the right in the United States. This is a follow up to a previous project in which I analyzed whether energy portfolios differed between red states and blue states (https://github.com/alab5037/Red-or-Blue/blob/master/Report%20(update).pdf ). Here's an excerpt from the paper regarding the conclusion of my study:\n",
    "\n",
    "\"In conclusion, this study makes a strong case that blue states generate more electricity from biomass than red states. It can be argued that red states generate more power from coal compared to blue states, but the argument is a bit more tenuous considering the significance level for the covariate coal in Table 1 of the logistic regression model.\"\n",
    "\n",
    "As stated above, I found evidence that energy policies differ between red and blue states as it pertains to clean/renewable energy--particularly, the adoption of biomass energy (waste, biofuels, etc.). Renewable energy proliferation is directly related to climate change since they are \"net-zero\", meaning that carbon dioxide and other greenhouse gas emissions are reduced 100% (Sims, 2003). To follow up on this research, I thought it would be interesting to further explore the political divide surrounding climate change. This time, I would like to get a better understanding of why it exists and where we stand today. To obtain insight on these questions, I explore the rhetoric of climate change articles from two mass media sites on different sides of the political spectrum: Fox News (right) and the Huffington Post (left). Fox News has been alleged by many to have a Republican Party bias in their news coverage; thus, it will be used as the right leaning media outlet in this study. Conversely, the Huffington Post has been said to be a liberal news and information site; hence, it will serve as the left leaning media outlet in this study. Where these media outlets lie on the political spectrum can be viewed in the following link: https://guides.lib.umich.edu/c.php?g=637508&p=4462444. \n",
    "\n",
    "Previous studies suggest that the conservative media tends to downplay climate change. For example, a 2007 and 2008 analysis found that Fox News takes a more dismissive tone towards climate change than CNN and MSNBC, which are both left leaning (Feldman, Lauren, et al., 2011). Interestingly, this seems to have quite an influence on how conservatives perceive climate change. In a 2010 Gallup survey of 1,014 adults in the U.S., 74% of liberals agreed that “effects of global warming are already occurring,” whereas only 30% of conservatives concurred (Jones, 2010). In this study, I would like to confirm whether these findings still hold true in 2019. If the message surrounding climate change proves to be different between both media outlets, then it would suggest that this divide still exists. This might also explain why energy portfolios differ between blue and red states as evidence shows that the media impacts how people vote. For instance, a 2007 paper, titled, \"The Fox News Effect: Media Bias and Voting,\" found that the introduction of Fox News to cable programming led to an increase in the share of votes in Presidential elections between 1996 and 2000. In particular, Republicans gained 0.4 to 0.7 percentage points in the towns that broadcast Fox News (DellaVigna and Kaplan, 2007). \n",
    "\n",
    "Ultimately, the goal of this study is not to point fingers at any one party. I think that both sides bare responsibility for the current state of affairs. As mentioned before, studies have shown that right leaning media outlets tend to be more dismissive of climate change. However, it is also said that liberals push too hard and exaggerate climate change fears which can be counterproductive (Kreutzer, 2016). I hope that my results can help to stress that tackling climate change requires political unity. If both sides of the political spectrum cannot align, it will be arduous to take effective action against climate change. \n",
    "\n",
    "To begin my study, I will first scrape climate change related articles from both Fox News and the Huffington Post. Once I’ve gathered this information, I will build statistical models to determine whether I can predict the source of the article based on the entire text of the article. A succesful model would point out these two political factions have different agendas when it comes to climate change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Scraping Fox News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I scraped articles from Fox News' climate change section. In the cell below, I create a function that allows me to load articles on the climate change section. This can be done by manipulating the offset parameter. I also include the JSON decoder in order to simplify the formatting of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "def fox_df(offset):\n",
    "    url = (\"https://www.foxnews.com/api/article-search?isCategory=false&isTag=true&isKeyword=false&\"\n",
    "    \"isFixed=false&isFeedUrl=false&searchSelected=fox-news%2Fus%2Fenvironment%2Fclimate-change&contentTypes=%7B\"\n",
    "    \"%22interactive%22:true,%22slideshow%22:true,%22video%22:true,%22article%22:true%7D&\"\n",
    "    \"size=30&offset=0\")\n",
    "    \n",
    "    url = url.replace('offset=0', 'offset=%s' % offset)\n",
    "    \n",
    "    r_fox = requests.get(url)\n",
    "    new_df_fox = json_normalize(r_fox.json())\n",
    "    \n",
    "    return new_df_fox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I generate a loop that loads 500 articles in batches of 30. The articles are in chronological order, so, the first 30 loaded, for example, will be the 30 most recently posted articles on Fox News. These articles are then all store in a dataframe, foxdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep # for pausing\n",
    "\n",
    "# create empty dataframe to store results\n",
    "foxdf = pd.DataFrame() \n",
    "\n",
    "# Create a loop that counts up by 30.\n",
    "for offset in range(0, 500, 30):\n",
    "    new_df = fox_df(offset)\n",
    "    \n",
    "    # Add the new results to the existing database\n",
    "    foxdf = foxdf.append(new_df, ignore_index=True)\n",
    "    \n",
    "    # Pause for three seconds to be polite to the web server\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "284 articles were loaded in the dataframe, meaning that only 284 were available on Fox News. Nonetheless, this should be ample for this analysis. However, I don't find that the available variables will serve as very good predictors for my model. For example, descriptions and titles do not seem to contain enough information to differentiate between Fox News and Huffington Post. As a result, I will retrieve the text of the articles in subsequent steps since these will be rich with information. Lastly, in the dataframe above, publisher information is not clearly available. This is ultimately what I want to serve as my dependent variable in my model. Therefore, I will create a new column for publisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxdf #add a column for publisher = 'fox'\n",
    "foxdf['publisher']='fox'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve text from each individual article, I create a list containing the links from the 'url' column in the fox dataframe. I notice, however, that some of these links direct you to videos, which, of course, don't contain much text. Hence, I will first remove links from the dataframe that are videos. These are identified by containing \"https\" in the url. After doing so, the dataframe has been reduce to 222 articles. I also need to change the index of the newly created dataframe, rm_video, to have consecutive numbers or else the loop won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows that include video links in url\n",
    "rm_video=foxdf[~foxdf.url.str.contains(\"https\")]\n",
    "#change index to have consecutive numbers \n",
    "rm_video.index = range(len(rm_video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I create a loop that stores links in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url='https://www.foxnews.com' #create fox base url (domain name), we can append paths to this\n",
    "links_fox=[]\n",
    "\n",
    "#create a df that stores all of the links into one df\n",
    "for i in range(0,len(rm_video)): \n",
    "        row=rm_video['url'][i] #path of each article\n",
    "        full_url=url+row #append path to domain\n",
    "        links_fox.append(full_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have all article links, I can extract text from them. I do this using the newspaper.article package, which makes it easy to pull the aformentioned data from the links. In addition to this, I will extract article titles and descrptions from the links. This should provide some background for each article, making it easier to identify. This data will be stored in a new dataframe, fox. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from newspaper.article import ArticleException, ArticleDownloadState\n",
    "\n",
    "article_info_fox=[] #empty list to store title/descpription of each individual article\n",
    "df_fox=[] #combine data from all of these articles into one list then convert to df\n",
    "\n",
    "for i in range(0,len(links_fox)): \n",
    "    article_fox = Article(links_fox[i]) #iterate through each article link\n",
    "        \n",
    "    slept = 0\n",
    "    article_fox.download()\n",
    "    while article_fox.download_state == ArticleDownloadState.NOT_STARTED:\n",
    "    # Raise exception if article download state does not change after 10 seconds\n",
    "        if slept > 9:\n",
    "            raise ArticleException('Download never started')\n",
    "    sleep(1)\n",
    "    slept += 1\n",
    "    \n",
    "    article_fox.parse() #makes it easy to identify main components of article\n",
    "       \n",
    "    #to retrieve title/description/full text from each article + append publisher name\n",
    "    article_info_fox={'title' : article_fox.title, \n",
    "                      'description': article_fox.meta_description,\n",
    "                      'text':article_fox.text,\n",
    "                      'publisher' : 'fox'} \n",
    "\n",
    "    df_fox.append(article_info_fox)\n",
    "    fox = pd.DataFrame(df_fox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Scraping Huffington Post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will scrape articles from the Huffington Post. As mentioned previously, the Huffington Post represents a left leaning media site, and, thus, will serve as the counterpart to Fox News. The goal is to end up with the same type of dataframe as Fox News with columns for description, publisher, text, and title. In the cell below, I use the Article command from the newspaper package. Moreover, I use the BeautifulSoup package to parse through each html page. I first define the function for collecting the information and then run it in a loop over all URLs. Since there are 26 articles per page, I need at least 9 pages to retrieve 222 articles--the same as Fox News. You can see that I loop through 11 pages (286 articles), to make sure I have enough articles just in case I have to remove those that are videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now on page1\n",
      "Now on page2\n",
      "Now on page3\n",
      "Now on page4\n",
      "Now on page5\n",
      "Now on page6\n",
      "Now on page7\n",
      "Now on page8\n",
      "Now on page9\n",
      "Now on page10\n",
      "Now on page11\n"
     ]
    }
   ],
   "source": [
    "#Scraping Huffington Post\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from newspaper import Article\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "store_pages=[] #store html code for each page\n",
    "\n",
    "for page_number in range(1,12): \n",
    "     \n",
    "    page_number=str(page_number) #convert integer to string (Request command only reads strings)\n",
    "    base_url_huff='https://www.huffpost.com/impact/topic/climate-change?page='\n",
    "    r_huff = Request(base_url_huff + page_number, headers={'User-Agent': 'Mozilla/5.0'}) #To get around block\n",
    "    webpage = urlopen(r_huff).read()\n",
    "    page_soup=soup(webpage,\"html.parser\")\n",
    "    store_pages.append(page_soup) #store each html parsed page in dataframe\n",
    "\n",
    "    print('Now on page' + page_number)\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what was done in the Fox News scraping, I retrieve article titles and descriptions by first retrieving links to each article. The stored links (285) can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_huff = [] #empty list to store links\n",
    "i=0\n",
    "for i in range(0, len(store_pages)):\n",
    "    for link in store_pages[i].findAll(\"a\", {\"class\": \"card__link yr-card-headline\"}):\n",
    "        links_huff.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I retrieve article titles and descriptions from each link. Again, the article package makes it easy to identify main components of the article. Here, I'm interested in obtaining the article title, description, text. I also include a publisher column labeled, huff, which will serve as my dependent variable in my analysis in the next section. Lastly, I combine data from all of these articles into one list then convert to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper.article import ArticleException, ArticleDownloadState\n",
    "\n",
    "article_info_huff=[] #empty list to store title/descpription/text of each individual article\n",
    "df_huff=[]\n",
    "\n",
    "for i in range(0,len(links_huff)): \n",
    "    article_huff = Article(links_huff[i]) #iterate through each article link\n",
    "        \n",
    "    slept = 0\n",
    "    article_huff.download()\n",
    "    while article_huff.download_state == ArticleDownloadState.NOT_STARTED:\n",
    "    # Raise exception if article download state does not change after 10 seconds\n",
    "        if slept > 9:\n",
    "            raise ArticleException('Download never started')\n",
    "    sleep(1)\n",
    "    slept += 1\n",
    "    \n",
    "    article_huff.parse() \n",
    "        \n",
    "    article_info_huff={'title' : article_huff.title, \n",
    "                      'description': article_huff.meta_description,\n",
    "                      'text': article_huff.text,\n",
    "                      'publisher' : 'huff'} \n",
    "\n",
    "    df_huff.append(article_info_huff)\n",
    "    huff = pd.DataFrame(df_huff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have dataframes for both Fox News and Huffington Post, I can combine them. However, before doing so I will remove some rows from the Huffington Post (285) to match the number of rows in the Fox News dataframe (222). I do this because I want a balanced dataset. The trimmed dataframe is called new_huff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_huff=huff[0:222]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have both dataframes for Fox News and the Huffington Post each containing the same features, I can combine them into one dataframe. The combined dataframe can be seen below and will be used for my analysis. In total, there are 444 rows since the Fox News and Huffington Post dataframs have 222 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append both df\n",
    "combine=fox.append(new_huff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I save the dataframe to a csv file for backup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "combine.to_csv(\"/Users/halabanz/Desktop/fox_huff-scrape2.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my data, I can perform various statistical analyses in order to ascertain the source of an article,  Fox News or Huffington Post. I will first create an array of dummy variables using the count vectorizer. The count vectorizer counts the number of times a token shows up in the document and uses this value as its weight. Furthermore, I will also implement the tfidf vectorizer which is similar to the count vectorizer, but now the weight also depends on the occurrence of a word in the entire corpora. With this newly created array, I will try to predict whether a given article belongs to Fox News or Huffington Post. In this study, I will use three models: 1) multinomial naive bayes 2) k nearest neighbors 3) random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "combine=pd.read_csv(\"/Users/halabanz/Desktop/Big Data/fox_huff-scrape.csv\")\n",
    "combine.drop(combine.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting started, for my dependent variable, publisher, I convert from string type to numeric type. In this case, articles belonging to Fox News will be labeled '1' and articles belonging to Huffington Post will be labeled '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    222\n",
       "0    222\n",
       "Name: publisher, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.loc[combine['publisher']=='fox','publisher']=1\n",
    "combine.loc[combine['publisher']=='huff','publisher']=0\n",
    "combine['publisher'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I randomly split my dataset into a training set (80% of dataframe) and a test set (20% of dataframe). The training set will be used to train my model (i.e. search for patterns) and the test set will be used to test the predictive strength and accuracy of my model. I do this until the number is somewhat balanced (45 vs 44)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45\n",
       "1    44\n",
       "Name: publisher, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(combine, test_size=0.2)\n",
    "train['publisher'].value_counts()\n",
    "test['publisher'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I create a list of stop words. Stop words are important because they remove common words that are not really useful for the analysis like 'a' and 'the'. I also included other words as stop words that could impact the analysis. For example, I found that 'fox' often appears in Fox News articles. However, this word does not have anything to do with the rhetoric regarding climate change and, thus, should not contribute to the model. The same goes for other words like 'getty' which is simply the author of article photos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "list_stop=['___','getty','huffpost','huff','huffington','fox','https','click','facebook','twitter']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(list_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Count Vectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I create create my array of variables using the count vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(lowercase = True,\n",
    "stop_words = stop_words,\n",
    "min_df = 2,\n",
    "ngram_range = (1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincv=cv.fit_transform(train['text'])\n",
    "x_testcv=cv.transform(test['text'])\n",
    "\n",
    "y_traincv=train['publisher']\n",
    "y_traincv=y_traincv.astype('int')\n",
    "\n",
    "y_testcv=test['publisher']\n",
    "y_testcv=y_testcv.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.1 Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb=MultinomialNB()\n",
    "mnb.fit(x_traincv,y_traincv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the multinomial naive bayes model using the count vectorizer array achieved nearly 100% accuracy. This, however, is on the training data, so this isn't so impressive. To truly test the model, I run it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9746478873239437\n"
     ]
    }
   ],
   "source": [
    "pred_mnbcv_train=mnb.predict(x_traincv)\n",
    "print(accuracy_score(y_traincv, pred_mnbcv_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy drops about 10 percentage points, but the predictive power is still quite good. Furthermore, the fall in accuracy tells us that our model is not overfitting the data. Based on this model, I think it's fair to say that there is a difference in climate change rhetoric between Fox News and the Huffington Post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8876404494382022\n"
     ]
    }
   ],
   "source": [
    "predmnbcv_test=mnb.predict(x_testcv)\n",
    "print(accuracy_score(y_testcv, predmnbcv_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix is not so interesting in this case as it looks like the true postive, false positive, and false negative rates are all pretty similar for both Fox News and Huffington Post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1\n",
       "Actual           \n",
       "0          39   6\n",
       "1           4  40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_values=np.array(y_testcv) \n",
    "actual_range = range(len(actual_values))\n",
    "\n",
    "y_testcv.index=actual_range #need to reorder index so it matches with pred\n",
    "\n",
    "actual = pd.Series(y_testcv, name='Actual')\n",
    "prediction_mnbcv= pd.Series(mnb.predict(x_testcv), name='Predicted')\n",
    "df_confusion_mnbcv = pd.crosstab(actual, prediction_mnbcv)\n",
    "df_confusion_mnbcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I explore how the language between both sites actually differ by examining the coefficients of the model. The coefficients are essentially the log of the estimated probability of a feature given the positive class. Since Fox News is labeled as '1' (positive class) and the coefficients listed below are negative, the model conveys that if an article contains 'peddle', for example, then it is less likely to be classified as a Fox News article. In other words, they are more likely to be found in Huffington Post articles. Because there are many words with coefficient around -11, it would be difficult to make a general statement about what they all mean in regards to climate change. However, if I pick out a few words like 'critical habitat', 'corals perish','people displaced','extensive flooding', etc. an argument can be made that these words convey the adverse impacts of climate change. This makes sense as we would expect the Huffington Post, a liberal media outlet, to push for climate change action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kiboshed effort          -11.429739\n",
       "peddle                   -11.429739\n",
       "culturally               -11.429739\n",
       "cultural                 -11.429739\n",
       "cult claimed             -11.429739\n",
       "cult                     -11.429739\n",
       "peddling                 -11.429739\n",
       "pegged                   -11.429739\n",
       "pegged number            -11.429739\n",
       "peatlands                -11.429739\n",
       "peggy                    -11.429739\n",
       "crumbling                -11.429739\n",
       "pennsylvania state       -11.429739\n",
       "pension                  -11.429739\n",
       "crown                    -11.429739\n",
       "pension funds            -11.429739\n",
       "pentagon                 -11.429739\n",
       "people according         -11.429739\n",
       "people care              -11.429739\n",
       "peninsula                -11.429739\n",
       "people climate           -11.429739\n",
       "cuomo                    -11.429739\n",
       "peace prize              -11.429739\n",
       "curtailed                -11.429739\n",
       "passionate               -11.429739\n",
       "past couple              -11.429739\n",
       "past month               -11.429739\n",
       "past months              -11.429739\n",
       "currently used           -11.429739\n",
       "currently responsible    -11.429739\n",
       "                            ...    \n",
       "criticized republicans   -11.429739\n",
       "people dying             -11.429739\n",
       "people feel              -11.429739\n",
       "people governments       -11.429739\n",
       "people impacted          -11.429739\n",
       "critical habitat         -11.429739\n",
       "critical climate         -11.429739\n",
       "people just              -11.429739\n",
       "crisis scientists        -11.429739\n",
       "crisis driven            -11.429739\n",
       "crisis decade            -11.429739\n",
       "people lives             -11.429739\n",
       "people nation            -11.429739\n",
       "people people            -11.429739\n",
       "people rise              -11.429739\n",
       "people said              -11.429739\n",
       "passed tenants           -11.429739\n",
       "passed set               -11.429739\n",
       "pass legislation         -11.429739\n",
       "cut global               -11.429739\n",
       "outside window           -11.429739\n",
       "outskirts                -11.429739\n",
       "davos switzerland        -11.429739\n",
       "davos                    -11.429739\n",
       "davies said              -11.429739\n",
       "davies director          -11.429739\n",
       "davies                   -11.429739\n",
       "overdue                  -11.429739\n",
       "outside white            -11.429739\n",
       "david easterling         -11.429739\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeficients_mnbcv = pd.Series(mnb.coef_[0],\n",
    "index=cv.get_feature_names())\n",
    "coeficients_mnbcv.sort_values()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.2 K Nearest Neighbor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I implement the k nearest neighbor (knn) algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier.fit(x_traincv, y_traincv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8084507042253521\n"
     ]
    }
   ],
   "source": [
    "#on training data\n",
    "knn_train_prediction_cv = knn_classifier.predict(x_traincv)\n",
    "print(accuracy_score(y_traincv, knn_train_prediction_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halabanz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction    0    1\n",
       "publisher           \n",
       "0           148   29\n",
       "1            39  139"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['prediction'] = knn_classifier.predict(x_traincv)\n",
    "pd.crosstab(train['publisher'], train['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6404494382022472\n"
     ]
    }
   ],
   "source": [
    "#on test data\n",
    "knn_test_prediction_cv = knn_classifier.predict(x_testcv)\n",
    "print(accuracy_score(y_testcv, knn_test_prediction_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0   1\n",
       "publisher        \n",
       "0          25  20\n",
       "1          12  32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['publisher'], knn_test_prediction_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn performs considerably worse than the naive bayes model, even after adjusting the number of clusters. For the test data, its accuracy falls around 15%. Taking a look at the confusion matrix for the test data indicates that there are a large proportion of false positive. That is, the model incorrectly classified 20 Huffington Post articles as Fox News articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.3 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last model in the count vectorized data, I use a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halabanz/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_traincv, y_traincv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf=rf.predict(x_testcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741573033707865"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for i in range (len(pred_rf)):\n",
    "    if pred_rf[i]==actual[i]:\n",
    "        count=count+1\n",
    "        \n",
    "numerator=count\n",
    "denominator=len(pred_rf)\n",
    "numerator/denominator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>0.019601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald</th>\n",
       "      <td>0.018457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life real</th>\n",
       "      <td>0.010353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0.008882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.008705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app</th>\n",
       "      <td>0.008114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real life</th>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help tell</th>\n",
       "      <td>0.007846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>federal</th>\n",
       "      <td>0.007523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>began</th>\n",
       "      <td>0.007458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remarks</th>\n",
       "      <td>0.007247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate</th>\n",
       "      <td>0.006912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catastrophic climate</th>\n",
       "      <td>0.006587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primary</th>\n",
       "      <td>0.006476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paradise</th>\n",
       "      <td>0.006048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catastrophic</th>\n",
       "      <td>0.006002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protection agency</th>\n",
       "      <td>0.005607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>0.005541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunrise movement</th>\n",
       "      <td>0.005516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news app</th>\n",
       "      <td>0.005514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.005441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>0.005328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real news</th>\n",
       "      <td>0.004881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pic com</th>\n",
       "      <td>0.004858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green new</th>\n",
       "      <td>0.004785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>called green</th>\n",
       "      <td>0.004759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wage</th>\n",
       "      <td>0.004574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>0.004551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existence climate</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existence</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exist</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhibit</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercise</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expectations</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exemptions</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exemption</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exempt</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>executives</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>executive order</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>executive director</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existential threat</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existing buildings</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existing fossil</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existing research</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exists</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exit</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exit paris</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expand</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expanded</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expanding</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expanding population</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expansion</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expansive</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expect</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expect people</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expectancy</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zones</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18686 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "donald trump            0.019601\n",
       "donald                  0.018457\n",
       "life real               0.010353\n",
       "2020                    0.008882\n",
       "life                    0.008705\n",
       "app                     0.008114\n",
       "real life               0.008000\n",
       "help tell               0.007846\n",
       "federal                 0.007523\n",
       "began                   0.007458\n",
       "remarks                 0.007247\n",
       "candidate               0.006912\n",
       "catastrophic climate    0.006587\n",
       "primary                 0.006476\n",
       "paradise                0.006048\n",
       "catastrophic            0.006002\n",
       "trump                   0.006000\n",
       "protection agency       0.005607\n",
       "start                   0.005541\n",
       "sunrise movement        0.005516\n",
       "news app                0.005514\n",
       "address                 0.005441\n",
       "old                     0.005328\n",
       "real news               0.004881\n",
       "pic com                 0.004858\n",
       "green new               0.004785\n",
       "called green            0.004759\n",
       "wage                    0.004574\n",
       "school                  0.004551\n",
       "president               0.004400\n",
       "...                          ...\n",
       "existence climate       0.000000\n",
       "existence               0.000000\n",
       "exist                   0.000000\n",
       "exhibit                 0.000000\n",
       "exercise                0.000000\n",
       "expectations            0.000000\n",
       "exemptions              0.000000\n",
       "exemption               0.000000\n",
       "exempt                  0.000000\n",
       "executives              0.000000\n",
       "executive order         0.000000\n",
       "executive director      0.000000\n",
       "existential threat      0.000000\n",
       "existing                0.000000\n",
       "existing buildings      0.000000\n",
       "existing fossil         0.000000\n",
       "existing research       0.000000\n",
       "exists                  0.000000\n",
       "exit                    0.000000\n",
       "exit paris              0.000000\n",
       "expand                  0.000000\n",
       "expanded                0.000000\n",
       "expanding               0.000000\n",
       "expanding population    0.000000\n",
       "expansion               0.000000\n",
       "expansive               0.000000\n",
       "expect                  0.000000\n",
       "expect people           0.000000\n",
       "expectancy              0.000000\n",
       "zones                   0.000000\n",
       "\n",
       "[18686 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances1 = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = cv.get_feature_names(),\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model performs relatively poorly with an accuracy of around 67%. I also took a look at what words were most important in classifying the origins of the article. However, these features don't really make sense to me and dont provide insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we run the same three models, but this time on tfidf vectorized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf method\n",
    "tf=TfidfVectorizer(min_df = 2,\n",
    "stop_words=stop_words,\n",
    "ngram_range = (1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=frozenset({'several', 'yourself', 'neither', 'whoever', 'whither', 'take', 'may', 'de', 'every', 'thereafter', 'here', 'yours', 'seeming', 'would', 'am', 'therefore', 'seem', 'put', 'few', 'her', 'afterwards', 'nothing', 're', 'ie', 'thick', 'onto', 'six', 'everyone', 'per', 'our', 'off',...three', 'see', 'against', 'huff', 'own', 'below', 'eleven', 'might', 'whatever', 'now', 'latterly'}),\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit(train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traintf=tf.transform(train['text'])\n",
    "x_testtf=tf.transform(test['text'])\n",
    "\n",
    "y_traintf=train['publisher']\n",
    "y_traintf=y_traintf.astype('int')\n",
    "\n",
    "y_testtf=test['publisher']\n",
    "y_testtf=y_testtf.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2.1 Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the multinomial naive bayes model is run on tfidf vectorized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(x_traintf,y_traintf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9633802816901409\n"
     ]
    }
   ],
   "source": [
    "pred_mnbtf_train=mnb.predict(x_traintf)\n",
    "print(accuracy_score(y_traintf, pred_mnbtf_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8876404494382022\n"
     ]
    }
   ],
   "source": [
    "pred_mnbtf_test=mnb.predict(x_testtf)\n",
    "print(accuracy_score(y_testtf, pred_mnbtf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1\n",
       "Actual           \n",
       "0          38   7\n",
       "1           3  41"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_mnbtf = pd.Series(mnb.predict(x_testtf), name='Predicted')\n",
    "df_confusion_mnbtf = pd.crosstab(actual, prediction_mnbtf)\n",
    "df_confusion_mnbtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeficients_mnbtf = pd.Series(mnb.coef_[0],\n",
    "index=tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the model performs similarly to the last in terms of accuracy. Furthermore, many of the same words have large coefficients. The number of false positives increases slightly, but it is nothing to be concerned about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2.2 K Nearest Neighbour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier_tf = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier_tf.fit(x_traintf, y_traintf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9042253521126761\n"
     ]
    }
   ],
   "source": [
    "knn_train_prediction_tf = knn_classifier_tf.predict(x_traintf)\n",
    "print(accuracy_score(y_traintf, knn_train_prediction_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8314606741573034\n"
     ]
    }
   ],
   "source": [
    "knn_test_prediction_tf = knn_classifier_tf.predict(x_testtf)\n",
    "print(accuracy_score(y_testtf, knn_test_prediction_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0   1\n",
       "publisher        \n",
       "0          37   8\n",
       "1           7  37"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['publisher'], knn_test_prediction_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we see that the knn model performs much better than in the previous case--accuracy has increased by nearly 20%. However, this model still underperforms compared to the naive bayes. This time, there are a similar number of false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2.3 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the random forest is conducted a second time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf.fit(x_traintf, y_traintf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf_tf=rf.predict(x_testtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7865168539325843"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for i in range (len(pred_rf_tf)):\n",
    "    if pred_rf_tf[i]==actual[i]:\n",
    "        count=count+1\n",
    "        \n",
    "numerator=count\n",
    "denominator=len(pred_rf_tf)\n",
    "numerator/denominator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances2 = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = tf.get_feature_names(),\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model improves quite a bit from the previous model (79% vs. 67%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, my results show that Fox News and the Huffington Post convey a different rhetoric regarding climate change. When models were applied to tfidf vectorized data, they achieved an average accuracy of approximately 84%. This is pretty good especially when considering that the most successful model (multinomial naive bayes) predicted nearly 89% of articles correctly.  \n",
    "\n",
    "On the other hand, it is a little more difficult to pinpoint how exactly the rhetoric differs. Using the entire text of articles allowed me to leverage more data and build stronger models, but interpretation is a tall order due to the sheer amount of features. From what I did find, however, it seems that the Huffington Post tends to focus on the negative impacts that climate change has on the environment compared to Fox News. This aligns with what previous research has shown.\n",
    "\n",
    "The take away from this study is that there still exists a considerable divide between the left and right as it pertains to climate change. This argument is strengthened when combined with the results from my previous study. Ultimately, I believe both sides need to align in order to see significant progress in tackling climate change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DellaVigna, Stefano, and Ethan Kaplan. “Fox News Effect: Media Bias and Voting *.” OUP Academic, Narnia, 1 Aug. 2007, https://www.nber.org/papers/w12169.pdf.\n",
    "\n",
    "Feldman, Lauren, et al. “Climate on Cable: The Nature and Impact of Global Warming Coverage on Fox News, CNN, and MSNBC - Lauren Feldman, Edward W. Maibach, Connie Roser-Renouf, Anthony Leiserowitz, 2012.” SAGE Journals, 2 Nov. 2011, journals.sagepub.com/doi/abs/10.1177/1940161211425410.\n",
    "\n",
    "Jones, J. M. (2010). Conservatives’ doubts about global warming grow. Gallup Poll. Retrieved August 3, 2014, from http://www.gallup.com/poll/126563/conservatives-doubts-global-warming-grow.aspx\n",
    "\n",
    "Kreutzer, David. “The State of Climate Science: No Justification for Extreme Policies.” The Heritage Foundation, 22 Apr. 2016, www.heritage.org/environment/report/the-state-climate-science-no-justification-extreme-policies.\n",
    "\n",
    "Sims, Ralph. “Renewable Energy: a Response to Climate Change.” Solar Energy, Pergamon, 24 Apr. 2003, www.sciencedirect.com/science/article/pii/S0038092X03001014.\n",
    "\n",
    "University of Michigan. “Fake News,\" Lies and Propaganda: How to Sort Fact from Fiction.” Research Guides, https://guides.lib.umich.edu/c.php?g=637508&p=4462444."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
